# ğŸ“„ RAG Backend â€“ PDF-based Question Answering

This is a **backend-only learning project** that implements a **Retrieval-Augmented Generation (RAG)** system.

This system supports secure **authentication**, **multi-chat conversations**,
**global** and **chat-specific document storage**, and **isolated RAG pipelines per user**.

---

## âœ¨ Features (Current Phase)

### ğŸ” Authentication
- User registration and login
- OAuth2 password flow
- JWT-based session management
- Secure Argon2 password hashing
- Registration limits and controls (for testing purposes)

### ğŸ’¬ Chat System
- Multiple chats per user
- Chat-based conversation structure
- User-level isolation

### ğŸ“„ Document Management
- Upload text-based PDF files
- Global document support
- Chat-specific document support
- Organized per-user storage
- Automatic ingestion into vector database

### ğŸ§  RAG Pipeline
- PDF text extraction
- Text chunking
- Embedding generation
- Vector storage using ChromaDB
- Metadata-based filtering
- Scoped retrieval (user + chat + global)

### ğŸ¤– LLM Integration
- Groq API
- Context-grounded responses
- Reduced hallucination behavior

---

## ğŸ§  Tech Stack

### Backend
- **Python 3**
- **FastAPI** â€“ REST API framework
- **Uvicorn** â€“ ASGI server

### Database
- **SQLite** (development)
- **SQLAlchemy ORM**

### Authentication
- **OAuth2PasswordBearer**
- **JWT (python-jose)**
- **Argon2 (passlib)**

### RAG Pipeline
- **PyPDF** â€“ PDF text extraction
- **Sentence-Transformers** â€“ local embeddings (`all-MiniLM-L6-v2`)
- **ChromaDB (local)** â€“ vector database
- **Groq API** â€“ LLM for answering questions

### Utilities
- **python-dotenv** â€“ environment variables
- **requests** â€“ API calls
- **python-multipart** â€“ file uploads
- **pydantic[email]** â€“ email-validator

---

## ğŸ“ Project Structure

    rag-chat-backend/
    â”‚
    â”œâ”€â”€ app/
    â”‚ â”œâ”€â”€ auth/ # Authentication
    â”‚ â”œâ”€â”€ chats/ # Chat management
    â”‚ â”œâ”€â”€ db/ # Database config
    â”‚ â”œâ”€â”€ documents/ # PDF storage
    â”‚ â”œâ”€â”€ rag/ # RAG pipeline
    â”‚ â””â”€â”€ main.py # App entry point
    â”‚
    â”œâ”€â”€ data/
    â”‚ â”œâ”€â”€ uploads/ # Uploaded PDFs (ignored by git)
    â”‚ â””â”€â”€ chroma/ # Vector DB data (ignored by git)
    â”‚
    â”œâ”€â”€ .env # API keys (not committed)
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ README.md


> âš ï¸ The `data/` directory is **intentionally ignored** and need to be regenerated at runtime.

---

## ğŸ” Environment Variables

Create a `.env` file in the project root:

```ini
GROQ_API_KEY=your_groq_api_key_here
SECRET_KEY=your_jwt_secret # for now its hardcoded but is best practice use env
```

---

## â–¶ï¸ Running Locally

### 1ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Start the server

```bash
uvicorn app.main:app --reload
```
Server will be available at: ```http://127.0.0.1:8000```

Swagger UI: ```http://127.0.0.1:8000/docs```

---

## ğŸ§ª API Usage Flow

Follow the steps below to use the system end-to-end.

---

### 1ï¸âƒ£ Register User

Create a new user account.

```bash
POST /auth/register
```

---

### 2ï¸âƒ£ Login

Authenticate and receive a JWT token.

```bash
POST /auth/login
```

The response contains:

```json
{
  "access_token": "...",
  "token_type": "bearer"
}
```

---

### 3ï¸âƒ£ Create Chat

Create a new chat session.

```bash
POST /chats
```
Request Body:

for shared data
```json
{
  "title": "My Notes",
  "scope": "global"
}
```
OR

for chat specific data
```json
{
  "title": "OS Notes",
  "scope": "chat"
}
```

---

### 4ï¸âƒ£ Upload PDF

Upload and ingest a PDF document.

```bash
POST /documents/upload/{chat_id}
```
- **chat_id** â†’ ID of the target chat
- File â†’ PDF document

The file is automatically processed and added to the vector database.

---

### 5ï¸âƒ£ Ask a Question

Query the RAG system.

```bash
POST /ask
```

Request body:
```json
{
  "chat_id": 2,
  "question": "Explain virtual memory"
}
```

The system retrieves relevant context and generates an answer.

---

---

## ğŸ“‚ Storage Layout

---

### File System Structure

Uploaded documents are organized as:

    data/
    â””â”€â”€uploads/
       â””â”€â”€user_id/
          â”œâ”€â”€global/ # context shared between chats
          â””â”€â”€chat_2/ # each separate non shared chat with id

---

### Vector Metadata Format

Each indexed chunk contains:

```ini
user_id = "1"
chat_id = "global" | "2"
```
This enables strict per-user and per-chat filtering.

---

## ğŸ”’ Security Model

The system enforces security at multiple layers:

- Argon2 password hashing
- JWT-based authentication
- OAuth2-compliant login flow
- Per-user authorization checks
- Chat ownership validation
- Scoped vector retrieval
- No cross-user data leakage

---

## âš ï¸ Current Limitations

The following features are intentionally not implemented yet:

- Persistent message history
- Source citation display
- Frontend user interface
- Streaming responses
- Production-grade database

These will be addressed in later phases.

---

## ğŸš€ Planned Enhancements

- Chat message persistence
- Source attribution and citations
- Automatic cleanup of old data/PDFs
- Usage quotas and rate limiting
- Admin management dashboard
- Deployment hardening
- Web frontend application

---

## ğŸ“Œ Purpose

This project is built to:
- Understand how **Retrieval-Augmented Generation (RAG)** works internally
- Learn **modern backend** architecture
- experiment with **LLMs and vector databases**
- Practice **secure authentication systems**
- Implement **production-style RAG pipelines**
- Understand **multi-tenant data isolation**
- serve as a **learning and portfolio project**

---

## âš ï¸ **Disclaimer**

This project is intended for learning and experimental use only.

It should not be deployed to production environments without
additional security reviews, performance testing, and monitoring.

---

